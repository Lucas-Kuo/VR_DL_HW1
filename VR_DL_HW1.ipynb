{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VR_DL-HW1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lucas-Kuo/VR_DL_HW1/blob/main/VR_DL_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1_kyD4qFj4Y"
      },
      "source": [
        "!git clone https://github.com/Lucas-Kuo/VR_DL_HW1.git\n",
        "%cd VR_DL_HW1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18XkHG7q5mUU"
      },
      "source": [
        "!pip install gdown\n",
        "!pip install imutils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xokDhuPi6gX4"
      },
      "source": [
        "import gdown\n",
        "# Download the training and testing dataset from my google drive\n",
        "url = \"https://drive.google.com/u/0/uc?id=1dYt4iLy0euxVXordHq4RRHgWojgUjgIf&export=download\"\n",
        "output = \"2021VRDL_HW1_datasets.zip\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "url = \"https://drive.google.com/u/0/uc?id=1yV3Bz5hpsJgwpplQARsCxVSnYxsRQALE&export=download\"\n",
        "output = \"checkpoints/checkpoints.data-00000-of-00001\"\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGFyaibN7JVz"
      },
      "source": [
        "!unzip 2021VRDL_HW1_datasets.zip\n",
        "!mkdir training_images\n",
        "!mkdir dataset\n",
        "!mkdir dataset/evaluation\n",
        "!unzip training_images.zip -d training_images\n",
        "!unzip testing_images.zip -d dataset/evaluation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTvXQTWwHJVJ"
      },
      "source": [
        "!python config.py\n",
        "!python build_dataset2.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdCM9ZLOgYVT"
      },
      "source": [
        "!python train_model.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AzEmpQBJr5K"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuxsYvYDRmMx"
      },
      "source": [
        "path = os.path.sep.join([\"self_utils\", \"sample_answer.txt\"])\n",
        "evaluation_filenames = []\n",
        "with open(path, \"r\") as f:\n",
        "  for line in f:\n",
        "    filename = line.split()[0]\n",
        "    evaluation_filenames.append(filename)\n",
        "evaluation_base_dir = os.path.sep.join([\"dataset\", \"evaluation\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqEBYgfWqFbg"
      },
      "source": [
        "# initialize the list of class label names\n",
        "CLASSES = []\n",
        "CLASS_NAMES_FILE = \"classes.txt\"\n",
        "with open(CLASS_NAMES_FILE, \"r\") as f:\n",
        "  for line in f:\n",
        "    line = line[:-1]\n",
        "    CLASSES.append(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZOtn_gaJvGt"
      },
      "source": [
        "PATH = \"dataset\"\n",
        "train_dir = os.path.join(PATH, \"training\")\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (600, 600)\n",
        "\n",
        "train_dataset = image_dataset_from_directory(train_dir, shuffle=True, class_names=CLASSES, label_mode=\"categorical\",\n",
        "                      batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
        "\n",
        "validation_dataset = image_dataset_from_directory(validation_dir, shuffle=True, class_names=CLASSES, label_mode=\"categorical\",\n",
        "                          batch_size=BATCH_SIZE, image_size=IMG_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUm3SKL-LH04"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh9P3JhZLJjf"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "  tf.keras.layers.RandomContrast(0.5, seed=None)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q70WVP6LRNu"
      },
      "source": [
        "# preprocess_input = tf.keras.applications.resnet_v2.preprocess_input\n",
        "preprocess_input = tf.keras.applications.efficientnet.preprocess_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM3acmljLRkx"
      },
      "source": [
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "# base_model = tf.keras.applications.ResNet152V2(input_shape=IMG_SHAPE,\n",
        "#                         include_top=False,\n",
        "#                         weights='imagenet')\n",
        "base_model = tf.keras.applications.efficientnet.EfficientNetB7(input_shape=IMG_SHAPE,\n",
        "                        include_top=False,\n",
        "                        weights='imagenet')\n",
        "# base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "#                         include_top=False,\n",
        "#                         weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBlcLs5XLYym"
      },
      "source": [
        "base_model.trainable = False\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqo6R0jdLfCw"
      },
      "source": [
        "# global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "average_layer = tf.keras.layers.AveragePooling2D(pool_size=(19, 19))\n",
        "prediction_layer = tf.keras.layers.Dense(len(CLASSES), activation=\"softmax\", activity_regularizer=tf.keras.regularizers.L2(0.1))\n",
        "\n",
        "inputs = tf.keras.Input(shape=(600, 600, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = average_layer(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxVl1bxOMTeK"
      },
      "source": [
        "base_learning_rate = 0.001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              # loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ7SLtRtTUaL"
      },
      "source": [
        "model.load_weights('./checkpoints/checkpoints')\n",
        "# loss, acc = model.evaluate(validation_dataset)\n",
        "# print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIDmjlNWYgb5"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "testDS = image_dataset_from_directory(\"dataset/evaluation\", labels=None, shuffle=False, label_mode=None, batch_size=BATCH_SIZE, image_size=IMG_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aZpJ5NrYhlE"
      },
      "source": [
        "predictions = model.predict(testDS)\n",
        "output = list(np.argmax(predictions, axis = 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPpvrNrqYvn_"
      },
      "source": [
        "result = {}\n",
        "N = len(output)\n",
        "for i in range(N):\n",
        "  name = testDS.file_paths[i][-8:] # the file path has the format: .../.../xxxx.jpg\n",
        "  label = CLASSES[output[i]]\n",
        "  result[name] = label\n",
        "\n",
        "with open(\"answer.txt\", \"w\") as f:\n",
        "  for filename in evaluation_filenames:\n",
        "    s = filename + ' ' + result[filename] + '\\n'\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl0jMItSwg8r"
      },
      "source": [
        "loss, acc = model.evaluate(validation_dataset)\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t14Dl_qPUUux"
      },
      "source": [
        "with open(\"answer.txt\", \"w\") as f:\n",
        "  for filename in evaluation_filenames[:10]:\n",
        "    imagePath = os.path.sep.join([evaluation_base_dir, filename])\n",
        "    image = tf.io.read_file(imagePath)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    image = tf.image.resize(image, IMG_SIZE)\n",
        "\n",
        "    evaluation_list = np.array([image])\n",
        "\n",
        "    prediction = model.predict(evaluation_list)\n",
        "    print(prediction[0][106])\n",
        "    # print(np.argmax(prediction, axis = 1))\n",
        "    # output = CLASSES[np.argmax(prediction, axis = 1)[0]]\n",
        "    # print(output)\n",
        "\n",
        "    answer = f\"{filename} {output}\\n\"\n",
        "    # print(answer)\n",
        "    # f.write(answer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GSzUBqjq-by"
      },
      "source": [
        "for filename in evaluation_filenames:\n",
        "  imagePath = os.path.sep.join([evaluation_base_dir, filename])\n",
        "  print(imagePath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nfgm9DP6aFRg"
      },
      "source": [
        "CLASSES[np.argmax(prediction, axis = 1)[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yt4pTuLqcTmf"
      },
      "source": [
        "p = \"dataset/validation/107.Common_Raven/1305.jpg\"\n",
        "image = tf.io.read_file(imagePath)\n",
        "image = tf.image.decode_jpeg(image, channels=3)\n",
        "image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "image = tf.image.resize(image, IMG_SIZE)\n",
        "\n",
        "evaluation_list = np.array([image])\n",
        "\n",
        "prediction = model.predict(evaluation_list)\n",
        "print(prediction)\n",
        "# print(np.argmax(prediction, axis = 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gucea_d3a-1P"
      },
      "source": [
        "evaluation_list = []\n",
        "for filename in evaluation_filenames:\n",
        "  imagePath = os.path.sep.join([evaluation_base_dir, filename])\n",
        "  image = tf.io.read_file(imagePath)\n",
        "  image = tf.image.decode_png(image, channels=3)\n",
        "  image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "  image = tf.image.resize(image, IMG_SIZE)\n",
        "  evaluation_list.append(image)\n",
        "\n",
        "evaluation_list = np.array(evaluation_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW39Fbk8beyi"
      },
      "source": [
        "predictions = model.predict(evaluation_list)\n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "predictions.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa0Qawe2miQy"
      },
      "source": [
        "len(base_model.layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiWWtxWXmsZI"
      },
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "fine_tune_at = 700\n",
        "\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5Wad47Um_q8"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              optimizer = tf.keras.optimizers.RMSprop(lr=base_learning_rate/10),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "len(model.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g96NbXXlnRgh"
      },
      "source": [
        "fine_tune_epochs = 30\n",
        "finetune_history = model.fit(train_dataset,\n",
        "          epochs=fine_tune_epochs,\n",
        "          validation_data=validation_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWlYtXO4nl_W"
      },
      "source": [
        "model.save_weights('./checkpoints2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsmUE2-yoGW1"
      },
      "source": [
        "acc = finetune_history.history['accuracy']\n",
        "val_acc = finetune_history.history['val_accuracy']\n",
        "\n",
        "loss = finetune_history.history['loss']\n",
        "val_loss = finetune_history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy(fine tuned)')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,6.0])\n",
        "plt.title('Training and Validation Loss(fine tuned)')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6JEbI8rMu9f"
      },
      "source": [
        "initial_epochs = 30\n",
        "\n",
        "# checkpoint_path = \"training_1/cp.ckpt\"\n",
        "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1)\n",
        "\n",
        "history = model.fit(train_dataset,\n",
        "          epochs=initial_epochs,\n",
        "          validation_data=validation_dataset)\n",
        "# os.makedirs('./checkpoints')\n",
        "# model.save_weights('./checkpoints/first_checkpoint')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9UFZNzbM5hw"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,6.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxLgfHaZi4Jm"
      },
      "source": [
        "\n",
        "model.save_weights('./checkpoints')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNr6b77roa7Q"
      },
      "source": [
        "# From here on, EfficientNetB4 is used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipnsVkEQpY4p"
      },
      "source": [
        "PATH = \"dataset\"\n",
        "train_dir = os.path.join(PATH, \"training\")\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (380, 380)\n",
        "\n",
        "train_dataset = image_dataset_from_directory(train_dir, shuffle=True, class_names=CLASSES, label_mode=\"categorical\",\n",
        "                      batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
        "\n",
        "validation_dataset = image_dataset_from_directory(validation_dir, shuffle=True, class_names=CLASSES, label_mode=\"categorical\",\n",
        "                          batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tW6tRF2pnSY"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "  tf.keras.layers.RandomContrast(0.5, seed=None)\n",
        "])\n",
        "\n",
        "preprocess_input = tf.keras.applications.efficientnet.preprocess_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7faMobjoNU4"
      },
      "source": [
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "base_model = tf.keras.applications.efficientnet.EfficientNetB4(input_shape=IMG_SHAPE,\n",
        "                        include_top=False,\n",
        "                        weights='imagenet')\n",
        "base_model.trainable = False\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOAaeWk4qDqF"
      },
      "source": [
        "average_layer = tf.keras.layers.AveragePooling2D(pool_size=(12, 12))\n",
        "prediction_layer = tf.keras.layers.Dense(len(CLASSES), activation=\"softmax\", activity_regularizer=tf.keras.regularizers.L2(0.1))\n",
        "\n",
        "inputs = tf.keras.Input(shape=(380, 380, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = average_layer(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o1ldWbmrxgj"
      },
      "source": [
        "base_learning_rate = 0.001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              # loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJi_s_1qr3sS"
      },
      "source": [
        "initial_epochs = 50\n",
        "history = model.fit(train_dataset,\n",
        "          epochs=initial_epochs,\n",
        "          validation_data=validation_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk0v3SentEkB"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,5.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKjWbM27GX3p"
      },
      "source": [
        "model.save_weights('./Enet_B4_checkpoint/B4_checkpoints')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55LCraTrHT_q"
      },
      "source": [
        "loss, acc = model.evaluate(validation_dataset)\n",
        "print(\"Acc of validation: {:5.2f}%\".format(acc * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0TEd9PaIIlM"
      },
      "source": [
        "p = \"dataset/training/087.Mallard/0712.jpg\"\n",
        "image = tf.io.read_file(p)\n",
        "image = tf.image.decode_jpeg(image, channels=3)\n",
        "image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "image = tf.image.resize(image, IMG_SIZE)\n",
        "\n",
        "evaluation_list = np.array([image])\n",
        "\n",
        "prediction = model.predict(validation_dataset)\n",
        "# print(prediction)\n",
        "print(np.argmax(prediction, axis = 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrRmuFHXJEzD"
      },
      "source": [
        "print(prediction[0][66])\n",
        "print(np.argmax(prediction, axis = 1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnAifUIQNtMp"
      },
      "source": [
        "def load_images(imagePath):\n",
        "  # read the image from disk, decode it, convert the data type to\n",
        "  # floating point, and resize it\n",
        "  image = tf.io.read_file(imagePath)\n",
        "  image = tf.image.decode_png(image, channels=3)\n",
        "  image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "  image = tf.image.resize(image, IMG_SIZE)\n",
        "\n",
        "  # parse the class label from the file path\n",
        "  label = None\n",
        "\n",
        "  # return the image and the label\n",
        "  return (image, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8ZlXYd6PA0m"
      },
      "source": [
        "from imutils import paths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN2ZYm8rPIOr"
      },
      "source": [
        "testPaths = list(paths.list_images(\"dataset/evaluation\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyIgrZwmOHqi"
      },
      "source": [
        "# build the testing dataset and data input pipeline\n",
        "testDS = tf.data.Dataset.from_tensor_slices(testPaths)\n",
        "testDS = (testDS\n",
        "\t.map(load_images, num_parallel_calls=AUTOTUNE)\n",
        "\t.cache()\n",
        "\t.batch(32)\n",
        "\t.prefetch(AUTOTUNE)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fynrECU1QDFT"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "testDS = image_dataset_from_directory(\"dataset/evaluation\", labels=None, shuffle=False, label_mode=None, batch_size=BATCH_SIZE, image_size=IMG_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRcvFj1BPWi2"
      },
      "source": [
        "predictions = model.predict(testDS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Sb7ZWsuPgfk"
      },
      "source": [
        "print(np.argmax(predictions, axis = 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--bK19eDR3fI"
      },
      "source": [
        "output = list(np.argmax(predictions, axis = 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85rAuLLvSm38"
      },
      "source": [
        "print(testDS.file_paths[0])\n",
        "# print(testDS.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jM3n4StS-tX"
      },
      "source": [
        "result = {}\n",
        "N = len(output)\n",
        "for i in range(N):\n",
        "  name = testDS.file_paths[i][-8:]\n",
        "  label = CLASSES[output[i]]\n",
        "  result[name] = label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiImxURPT8vf"
      },
      "source": [
        "result[\"3306.jpg\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJr1yUPaUT5V"
      },
      "source": [
        "with open(\"answer.txt\", \"w\") as f:\n",
        "  for filename in evaluation_filenames:\n",
        "    s = filename + ' ' + result[filename] + '\\n'\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}